{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "In this notebook, we will use Python to determine if there are data quality issues present or if there are any fields that are challenging to understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data based on input type\n",
    "def set_csv(input_type):\n",
    "    valid_types = {\n",
    "        \"users\": \"../raw-data/USER_TAKEHOME.csv\",\n",
    "        \"transactions\": \"../raw-data/TRANSACTION_TAKEHOME.csv\",\n",
    "        \"products\": \"../raw-data/PRODUCTS_TAKEHOME.csv\"\n",
    "    }\n",
    "    \n",
    "    if input_type not in valid_types:\n",
    "        raise ValueError(f\"Invalid type '{input_type}'. Expected one of {list(valid_types.keys())}\")\n",
    "    \n",
    "    return valid_types[input_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO THIS: Change csv_type input to either \"users\", \"transactions\", or \"products\"\n",
    "try:\n",
    "    csv_type = \"transactions\" \n",
    "    df = pd.read_csv(set_csv(csv_type))\n",
    "    # confirm the kind of data we're working with\n",
    "    print(f\"Successfully read {csv_type.upper()} CSV file. Continuing with analysis...\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data types of each column (to be compared to what we know the types should be)\n",
    "print(df.dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure columns in the csv files are of the correct data types\n",
    "# This will work with any of the files we choose to explore\n",
    "\n",
    "# Convert all columns containing 'DATE' in their name to timezone-aware datetime (UTC)\n",
    "date_columns = [col for col in df.columns if 'DATE' in col.upper()]  \n",
    "df[date_columns] = df[date_columns].apply(lambda x: pd.to_datetime(x, errors='coerce', utc=True))\n",
    "\n",
    "# Convert 'BARCODE' column to Int64 type (if we are looking at data with 'BARCODE' column)\n",
    "if 'BARCODE' in df.columns:\n",
    "    df['BARCODE'] = pd.to_numeric(df['BARCODE'], errors='coerce').astype('Int64')  # Ensure NaNs are handled\n",
    "    \n",
    "# Convert 'FINAL_QUANTITY' and 'FINAL_SALE' columns to numeric types (if we are looking at data with these columns)\n",
    "if 'FINAL_QUANTITY' in df.columns:\n",
    "    df['FINAL_QUANTITY'] = pd.to_numeric(df['FINAL_QUANTITY'], errors='coerce')  # Convert to numeric, coerce errors to NaN\n",
    "if 'FINAL_SALE' in df.columns:\n",
    "    df['FINAL_SALE'] = pd.to_numeric(df['FINAL_SALE'], errors='coerce')  # Convert to numeric, coerce errors to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format floating-point numbers to display with two decimal places\n",
    "if df.select_dtypes(include=['float64', 'float32']).shape[1] > 0:\n",
    "    pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 20 rows of the dataframe\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many missing values are in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many unique values are in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix between all numeric columns\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
